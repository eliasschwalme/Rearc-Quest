{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d760ac73",
   "metadata": {},
   "source": [
    "# Saving the files to S3 Bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265d8292",
   "metadata": {},
   "source": [
    "### Importing the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "297cf954",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import csv\n",
    "import boto3\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import functools\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ee791a",
   "metadata": {},
   "source": [
    "#### A decorator function for adding new methods to class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c984b4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_class(\n",
    "    main_class=None, exclude=(\"__module__\", \"__name__\",\"__dict__\",\"__weakref__\")\n",
    "):\n",
    "    def decorates(main_class, exclude, appended_class):\n",
    "        if main_class is None:\n",
    "            main_class = globals()[appended_class.__name__]\n",
    "        for k, v in appended_class.__dict__.items():\n",
    "            if k not in exclude:\n",
    "                setattr(main_class, k, v)\n",
    "        return main_class\n",
    "    return functools.partial(decorates, main_class, exclude)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de598f44",
   "metadata": {},
   "source": [
    "### Class constructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4926e134",
   "metadata": {},
   "outputs": [],
   "source": [
    "class manage_s3():\n",
    "    def __init__(self,bucket_name,url,key=None):\n",
    "        self.bucket_name = bucket_name\n",
    "        self.url = url\n",
    "\n",
    "        # AWS credentials as not needed as this script will run on AWS.\n",
    "        # For running on local machines please uncomment the following lines.\n",
    "        \n",
    "        if key:\n",
    "            with open(key, \"r\") as f:\n",
    "                self.AK,self.SK = [x.split()[0] for x in f.readlines()[-1].split(',')]\n",
    "            self.s3 = boto3.resource('s3',              \n",
    "                aws_access_key_id=self.AK, aws_secret_access_key=self.SK\n",
    "            )\n",
    "        else:\n",
    "            self.s3 = boto3.resource('s3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b6c345",
   "metadata": {},
   "source": [
    "### Get the file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "872575f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@update_class()\n",
    "class manage_s3():\n",
    "    def get_name(self):\n",
    "        soup = BeautifulSoup(requests.get(self.url).text, \"lxml\")\n",
    "        print(\"Reading file names complete.\")\n",
    "        return [page.string for page in soup.findAll('a', href=re.compile(''))[1:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb50e08",
   "metadata": {},
   "source": [
    "### Read the files from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9827a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "@update_class()\n",
    "class manage_s3():\n",
    "    def read_s3(self):\n",
    "        ret_dict = {}\n",
    "        # Create bucket if not exist, else get the bucket.\n",
    "        bucket = self.s3.create_bucket(Bucket=self.bucket_name)\n",
    "        for i,obj in enumerate(bucket.objects.all()):\n",
    "            ret_dict[obj.key] = obj.get()['Body'].read()\n",
    "        print(\"Reading s3 complete.\")\n",
    "        return ret_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2c365e",
   "metadata": {},
   "source": [
    "### Sync the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "539a945b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@update_class()\n",
    "class manage_s3():\n",
    "    def sync_files(self):\n",
    "        files = self.get_name()\n",
    "        s3_files = self.read_s3()\n",
    "        file_name = s3_files.keys()\n",
    "        \n",
    "        print(\"Uploading/Updating files to s3\")\n",
    "        \n",
    "        for i, f in enumerate(files):\n",
    "            with requests.get(self.url+f, stream=True) as r:\n",
    "                if f not in file_name:\n",
    "                    self.s3.Object(self.bucket_name, f).put(Body=r.content)\n",
    "                    print(f\"{i+1}) {f} uploaded\")\n",
    "                else:\n",
    "                    if r.content != s3_files[f]:\n",
    "                        self.s3.Object(self.bucket_name, f).put(Body=r.content)\n",
    "                        print(f\"{i+1}) {f} updated\")\n",
    "                    else:\n",
    "                        print(f\"{i+1}) {f} skipped\")\n",
    "        \n",
    "        print(\"Deleting files from s3\")\n",
    "        \n",
    "        del_f = [f for f in file_name if f not in files]\n",
    "        for i, f in enumerate(del_f):\n",
    "            self.s3.Object(self.bucket_name, f).delete()\n",
    "            print(f\"{i+1}) {f} deleted\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "364be306",
   "metadata": {},
   "outputs": [],
   "source": [
    "@update_class()\n",
    "class manage_s3():\n",
    "    def new_s3_add_files(self, bucket_name, url, key):\n",
    "        r = requests.get(url).text\n",
    "        self.s3.Object(bucket_name, key).put(Body=r)\n",
    "        print(f\"Data from given API is written to {bucket_name} bucket.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52417909",
   "metadata": {},
   "source": [
    "### Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3956de66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file names complete.\n",
      "Reading s3 complete.\n",
      "Uploading/Updating files to s3\n",
      "1) pr.class skipped\n",
      "2) pr.contacts skipped\n",
      "3) pr.data.0.Current skipped\n",
      "4) pr.data.1.AllData skipped\n",
      "5) pr.duration skipped\n",
      "6) pr.footnote skipped\n",
      "7) pr.measure skipped\n",
      "8) pr.period skipped\n",
      "9) pr.seasonal skipped\n",
      "10) pr.sector skipped\n",
      "11) pr.series skipped\n",
      "12) pr.txt skipped\n",
      "Deleting files from s3\n"
     ]
    }
   ],
   "source": [
    "key = \"srd22_accessKeys.csv\"\n",
    "bucket_name = \"s1quest\"\n",
    "res_url = \"https://download.bls.gov/pub/time.series/pr/\"\n",
    "\n",
    "s = manage_s3(bucket_name, res_url, key)\n",
    "s.sync_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46d10f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data from given url is written to s2quest bucket.\n"
     ]
    }
   ],
   "source": [
    "new_bucket = \"s2quest\"\n",
    "api = \"https://datausa.io/api/data?drilldowns=Nation&measures=Population\"\n",
    "file_key = \"data.json\"\n",
    "s.new_s3_add_files(new_bucket, api,file_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa23867b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
